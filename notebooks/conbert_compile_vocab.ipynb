{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConBERT vocabulary compilation\n",
    "This notebook reproduces creation of CondBERT vocabulary.\n",
    "\n",
    "The files `positive-words.txt`, `negative-words.txt` and `toxic_words.txt` are not reproduced exactly because of our internal issues. \n",
    "\n",
    "However, all other files (`token_toxicities.txt` and `word2coef.pkl` ) are reproduced accurately.\n",
    "\n",
    "Important note: The notebook use pseudo-absolute path and should be launched only once. So If you want to launch it second time, restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leon/Projects/Programming/Study/Python/ML_Inno/PMLDL/PML_ASS_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Upcast the path to the src folder\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:02.304607Z",
     "end_time": "2023-10-28T16:49:02.328967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def manual_seed(seed):\n",
    "    \"\"\"\n",
    "    Function to set the seed value for reproducibility\n",
    "    :param seed: seed value\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # PyTorch manual seed\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # NumPy manual seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# Set the seed value\n",
    "seed = 42\n",
    "\n",
    "# Call the manual seeding function\n",
    "manual_seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:02.306123Z",
     "end_time": "2023-10-28T16:49:02.330801Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_DIRNAME = 'models/Conbert/vocab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:02.306600Z",
     "end_time": "2023-10-28T16:49:06.201414Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.Conbert.conbert import CondBertRewriter\n",
    "from models.Conbert.choosers import EmbeddingSimilarityChooser\n",
    "from models.Conbert.multiword.masked_token_predictor_bert import MaskedTokenPredictorBert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:06.207603Z",
     "end_time": "2023-10-28T16:49:06.217321Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:11.032480Z",
     "end_time": "2023-10-28T16:49:11.038299Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:12.427812Z",
     "end_time": "2023-10-28T16:49:22.520372Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:31.874472Z",
     "end_time": "2023-10-28T16:49:53.344279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:53.359759Z",
     "end_time": "2023-10-28T16:49:54.198641Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the vocabularires.\n",
    "\n",
    "- negative-words.txt\n",
    "- positive-words.txt\n",
    "- word2coef.pkl\n",
    "- token_toxicities.txt\n",
    "\n",
    "These files should be prepared once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T20:30:33.812985Z",
     "end_time": "2023-10-28T20:30:33.855592Z"
    }
   },
   "outputs": [],
   "source": [
    "tox_corpus_path = 'data/interm/train_toxic_corpus.txt'\n",
    "norm_corpus_path = 'data/interm/train_normal_corpus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T20:30:33.853287Z",
     "end_time": "2023-10-28T20:30:33.860185Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(VOCAB_DIRNAME):\n",
    "    os.makedirs(VOCAB_DIRNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the DRG-like vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T20:30:33.873098Z",
     "end_time": "2023-10-28T20:30:33.914068Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from nltk import ngrams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "class NgramSalienceCalculator():\n",
    "    \"\"\"Calculates salience of ngrams in a corpus\"\"\"\n",
    "    def __init__(self, tox_corpus, norm_corpus, use_ngrams=False):\n",
    "        ngrams = (1, 3) if use_ngrams else (1, 1)\n",
    "        self.vectorizer = CountVectorizer(ngram_range=ngrams)\n",
    "\n",
    "        tox_count_matrix = self.vectorizer.fit_transform(tox_corpus)\n",
    "        self.tox_vocab = self.vectorizer.vocabulary_\n",
    "        self.tox_counts = np.sum(tox_count_matrix, axis=0)\n",
    "\n",
    "        norm_count_matrix = self.vectorizer.fit_transform(norm_corpus)\n",
    "        self.norm_vocab = self.vectorizer.vocabulary_\n",
    "        self.norm_counts = np.sum(norm_count_matrix, axis=0)\n",
    "\n",
    "    def salience(self, feature, attribute='tox', lmbda=0.5):\n",
    "        \"\"\"\n",
    "        Calculates salience of a feature\n",
    "        :param feature: input feature\n",
    "        :param attribute: attribute to calculate salience for\n",
    "        :param lmbda: smoothing parameter\n",
    "        :return: salience of a feature\n",
    "        \"\"\"\n",
    "        assert attribute in ['tox', 'norm']\n",
    "        if feature not in self.tox_vocab:\n",
    "            tox_count = 0.0\n",
    "        else:\n",
    "            tox_count = self.tox_counts[0, self.tox_vocab[feature]]\n",
    "\n",
    "        if feature not in self.norm_vocab:\n",
    "            norm_count = 0.0\n",
    "        else:\n",
    "            norm_count = self.norm_counts[0, self.norm_vocab[feature]]\n",
    "\n",
    "        if attribute == 'tox':\n",
    "            return (tox_count + lmbda) / (norm_count + lmbda)\n",
    "        else:\n",
    "            return (norm_count + lmbda) / (tox_count + lmbda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:54.483015Z",
     "end_time": "2023-10-28T16:49:56.143169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88645\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "\n",
    "for fn in [tox_corpus_path, norm_corpus_path]:\n",
    "    with open(fn, 'r') as corpus:\n",
    "        for line in corpus.readlines():\n",
    "            for tok in line.strip().split():\n",
    "                c[tok] += 1\n",
    "\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:59.153377Z",
     "end_time": "2023-10-28T16:49:59.186976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88645\n"
     ]
    }
   ],
   "source": [
    "vocab = {w for w, _ in c.most_common() if _ > 0}  # if we took words with > 1 occurences, vocabulary would be x2 smaller, but we'll survive this size\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:49:59.813490Z",
     "end_time": "2023-10-28T16:50:00.905275Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(tox_corpus_path, 'r') as tox_corpus, open(norm_corpus_path, 'r') as norm_corpus:\n",
    "    corpus_tox = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in tox_corpus.readlines()]\n",
    "    corpus_norm = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in norm_corpus.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:00.946877Z",
     "end_time": "2023-10-28T16:50:00.989555Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_out_name = VOCAB_DIRNAME + '/negative-words.txt'\n",
    "pos_out_name = VOCAB_DIRNAME + '/positive-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:01.792320Z",
     "end_time": "2023-10-28T16:50:01.798134Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:02.180821Z",
     "end_time": "2023-10-28T16:50:07.213889Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = NgramSalienceCalculator(corpus_tox, corpus_norm, False)\n",
    "seen_grams = set()\n",
    "\n",
    "with open(neg_out_name, 'w') as neg_out, open(pos_out_name, 'w') as pos_out:\n",
    "    for gram in set(sc.tox_vocab.keys()).union(set(sc.norm_vocab.keys())):\n",
    "        if gram not in seen_grams:\n",
    "            seen_grams.add(gram)\n",
    "            toxic_salience = sc.salience(gram, attribute='tox')\n",
    "            polite_salience = sc.salience(gram, attribute='norm')\n",
    "            if toxic_salience > threshold:\n",
    "                neg_out.writelines(f'{gram}\\n')\n",
    "            elif polite_salience > threshold:\n",
    "                pos_out.writelines(f'{gram}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating word toxicities with a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:07.217657Z",
     "end_time": "2023-10-28T16:50:07.265441Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:07.257347Z",
     "end_time": "2023-10-28T16:50:34.826950Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = corpus_tox + corpus_norm\n",
    "y_train = [1] * len(corpus_tox) + [0] * len(corpus_norm)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:34.826463Z",
     "end_time": "2023-10-28T16:50:34.830232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(88519,)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pipe[1].coef_[0]\n",
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:34.827666Z",
     "end_time": "2023-10-28T16:50:34.895964Z"
    }
   },
   "outputs": [],
   "source": [
    "word2coef = {w: coefs[idx] for w, idx in pipe[0].vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:35.088361Z",
     "end_time": "2023-10-28T16:50:35.121388Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(VOCAB_DIRNAME + '/word2coef.pkl', 'wb') as f:\n",
    "    pickle.dump(word2coef, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling BERT tokens by toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:50:47.934580Z",
     "end_time": "2023-10-28T16:52:43.352489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135390/135390 [00:57<00:00, 2351.64it/s]\n",
      "100%|██████████| 135390/135390 [00:57<00:00, 2341.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "toxic_counter = defaultdict(lambda: 1)\n",
    "nontoxic_counter = defaultdict(lambda: 1)\n",
    "\n",
    "for text in tqdm(corpus_tox):\n",
    "    for token in tokenizer.encode(text):\n",
    "        toxic_counter[token] += 1\n",
    "for text in tqdm(corpus_norm):\n",
    "    for token in tokenizer.encode(text):\n",
    "        nontoxic_counter[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:43.354855Z",
     "end_time": "2023-10-28T16:52:43.365207Z"
    }
   },
   "outputs": [],
   "source": [
    "token_toxicities = [toxic_counter[i] / (nontoxic_counter[i] + toxic_counter[i]) for i in range(len(tokenizer.vocab))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:43.366001Z",
     "end_time": "2023-10-28T16:52:43.546673Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(VOCAB_DIRNAME + '/token_toxicities.txt', 'w') as f:\n",
    "    for t in token_toxicities:\n",
    "        f.write(str(t))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:43.498580Z",
     "end_time": "2023-10-28T16:52:43.547021Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(VOCAB_DIRNAME + \"/negative-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "negative_words = list(map(lambda x: x[:-1], s))\n",
    "\n",
    "with open(VOCAB_DIRNAME + \"/positive-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "positive_words = list(map(lambda x: x[:-1], s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:43.540447Z",
     "end_time": "2023-10-28T16:52:43.626362Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(VOCAB_DIRNAME + '/word2coef.pkl', 'rb') as f:\n",
    "    word2coef = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:43.630319Z",
     "end_time": "2023-10-28T16:52:43.673120Z"
    }
   },
   "outputs": [],
   "source": [
    "token_toxicities = []\n",
    "with open(VOCAB_DIRNAME + '/token_toxicities.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        token_toxicities.append(float(line))\n",
    "token_toxicities = np.array(token_toxicities)\n",
    "token_toxicities = np.maximum(0, np.log(1/(1/token_toxicities-1)))   # log odds ratio\n",
    "\n",
    "# discourage meaningless tokens\n",
    "for tok in ['.', ',', '-']:\n",
    "    token_toxicities[tokenizer.encode(tok)][1] = 3\n",
    "\n",
    "for tok in ['you']:\n",
    "    token_toxicities[tokenizer.encode(tok)][1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:43.671614Z",
     "end_time": "2023-10-28T16:52:45.782946Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_logits(logits, label=0):\n",
    "    \"\"\"\n",
    "    Function that adjusts logits to make the model more sensitive to the label\n",
    "    :param logits: logits from the model\n",
    "    :param label: label to adjust logits to\n",
    "    :return: adjusted logits\n",
    "    \"\"\"\n",
    "    return logits - token_toxicities * 100 * (1 - 2 * label)\n",
    "\n",
    "predictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0, logits_postprocessor=adjust_logits)\n",
    "\n",
    "editor = CondBertRewriter(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    neg_words=negative_words,\n",
    "    pos_words=positive_words,\n",
    "    word2coef=word2coef,\n",
    "    token_toxicities=token_toxicities,\n",
    "    predictor=predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model below is used for reranking BERT hypotheses and helps to increase semantic similarity by choosing the hypotheses with  embeddings similar to the orignal words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:45.786386Z",
     "end_time": "2023-10-28T16:52:49.860817Z"
    }
   },
   "outputs": [],
   "source": [
    "chooser = EmbeddingSimilarityChooser(sim_coef=10, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, the inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel application of the model to all tokens, fast, but dirty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:49.863867Z",
     "end_time": "2023-10-28T16:52:51.266846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are mistake !\n"
     ]
    }
   ],
   "source": [
    "print(editor.translate('You are idiot!', prnt=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of the model to all the tokens sequentially, in the multiword mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-28T16:52:51.271358Z",
     "end_time": "2023-10-28T16:52:51.630175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are very beautiful !\n"
     ]
    }
   ],
   "source": [
    "print(editor.replacement_loop('You are stupid!', verbose=False, chooser=chooser, n_tokens=(1, 2, 3), n_top=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters that could be tuned:\n",
    "* The coeffincient in `adjust_logits` - the larger it is, the more the model avoids toxic words\n",
    "* The coefficient in `EmbeddingSimilarityChooser` - the larger it is, the more the model tries to preserve content \n",
    "* n_tokens - how many words can be generated from one\n",
    "* n_top - how many BERT hypotheses are reranked\n",
    "* n_top - how many BERT hypotheses are reranked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
